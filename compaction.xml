<!-- hive-sit.xml -->


<!-- Enable transactions -->
<property>
  <name>hive.support.concurrency</name>
  <value>true</value>
</property>

<property>
  <name>hive.enforce.bucketing</name>
  <value>true</value>
</property>

<property>
  <name>hive.exec.dynamic.partition.mode</name>
  <value>nonstrict</value>
</property>

<property>
  <name>hive.txn.manager</name>
  <value>org.apache.hadoop.hive.ql.lockmgr.DbTxnManager</value>
</property>

<!-- Lock manager for concurrency -->
<property>
  <name>hive.compactor.initiator.on</name>
  <value>true</value>
</property>

<property>
  <name>hive.compactor.worker.threads</name>
  <value>2</value>
</property>

<property>
  <name>hive.txn.timeout</name>
  <value>300</value>
</property>

<property>
  <name>hive.compactor.delta.num.threshold</name>
  <value>4</value>
</property>

<!-- Optional: compact every X minutes -->
<property>
  <name>hive.compactor.delta.pct.threshold</name>
  <value>0.1</value>
</property>


<!-- in creatinon Enable transactions -->

<!-- CREATE TABLE your_table (
  id INT,
  val STRING
)
CLUSTERED BY (id) INTO 3 BUCKETS
STORED AS ORC
TBLPROPERTIES ('transactional'='true'); -->


<!-- SET hive.txn.manager=org.apache.hadoop.hive.ql.lockmgr.DbTxnManager;
SET hive.support.concurrency=true;
SET hive.auto.convert.insert.delta=true; -->


<property>
  <name>hive.compactor.initiator.on</name>
  <value>true</value>
</property>

<property>
  <name>hive.compactor.worker.threads</name>
  <value>2</value>
</property>

<property>
  <name>hive.compactor.delta.num.threshold</name>
  <value>4</value> <!-- If more than 4 delta files -->
</property>

<property>
  <name>hive.compactor.delta.pct.threshold</name>
  <value>0.1</value> <!-- If delta files >10% of base size -->
</property>



<!-- to force compaction:
ALTER TABLE your_table COMPACT 'minor'; -->


<!-- it can be detecated compaction container for compaction -->

  <!-- compactor:
    build: 
      context: .
      target: hive
    container_name: hive_compactor
    hostname: compactor
    networks:
      - hnet
    depends_on:
      - postgres
      - m1
      - h1
    restart: always -->

<!-- entry point
    elif [[ "$HOSTNAME" == "compactor" ]]; then
        "hive", "--service", "compactor"
    fi -->



    <!-- -- Vectorization
set hive.vectorized.execution.enabled=true;
set hive.vectorized.execution.reduce.enabled=true;

<property>
  <name>hive.vectorized.execution.enabled</name>
  <value>true</value>
</property>
<property>
  <name>hive.vectorized.execution.reduce.enabled</name>
  <value>true</value>
</property>




-- LLAP (when configured)
set hive.execution.engine=tez;
set hive.llap.execution.mode=all; 

<property>
  <name>hive.llap.execution.mode</name>
  <value>all</value> <!-- can be "only", "none", "auto" -->
</property>

<property>
  <name>hive.llap.daemon.num.executors</name>
  <value>4</value>
</property>

<property>
  <name>hive.llap.io.memory.size</name>
  <value>1024</value> <!-- 1 GB IO cache -->
</property>

<property>
  <name>hive.llap.io.enabled</name>
  <value>true</value>
</property>

<property>
  <name>hive.llap.daemon.yarn.container.mb</name>
  <value>8192</value> <!-- 8 GB container -->
</property>



-->


<!-- 
need to start llap daemons
on the host where you have the HiveServer2 running
llap-daemon --name llap0 --instances 4 --cache 1024m --executors 4 --executor-size 2g --size 8g




in the beginning
-- Confirm engine
set hive.execution.engine;

-- Check vectorization status
set hive.vectorized.execution.enabled;

-- Force LLAP usage
set hive.llap.execution.mode=all;

-- View DAG for Tez jobs
set tez.view.dag.info=true;


llap-daemon --name llap0 \
  --instances 4 \
  --cache 1024m \
  --executors 4 \
  --executor-size 2g \
  --size 8g \
  --slider-am-container-mb 1024 \
  --loglevel INFO \
  --restart -->

