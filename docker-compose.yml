services:
  m1:
    build: 
      context: .
      target: hadoop
    container_name: m1
    hostname: m1
    networks:
      - hnet
    ports:
      - "9870:9870"
      - "8088:8088"
    volumes:
      - nn1:/usr/local/hadoop/hdfs/namenode
      - j1:/usr/local/hadoop/journal
      - zk1:/usr/local/zookeeper

    healthcheck:
      test: ["CMD", "/home/hadoop/health_check.sh"]
      interval: 7s
      timeout: 3s
      retries: 7
      start_period: 10s 
    # restart: always

  m2:
    build: 
      context: .
      target: hadoop
    container_name: m2
    hostname: m2
    networks:
      - hnet
    ports:
      - "9871:9870"
      - "8089:8088"
    volumes:
      - nn2:/usr/local/hadoop/hdfs/namenode
      - j2:/usr/local/hadoop/journal
      - zk2:/usr/local/zookeeper

    healthcheck:
      test: ["CMD", "/home/hadoop/health_check.sh"]
      interval: 7s
      timeout: 3s
      retries: 7
      start_period: 10s 
    depends_on:
      - m1
    # restart: always       

  m3:
    build: 
      context: .
      target: hadoop
    container_name: m3
    hostname: m3
    networks:
      - hnet
    ports:
      - "9872:9870"
      - "8090:8088"
    volumes:
      - nn3:/usr/local/hadoop/hdfs/namenode
      - j3:/usr/local/hadoop/journal
      - zk3:/usr/local/zookeeper

    healthcheck:
      test: ["CMD", "/home/hadoop/health_check.sh"]
      interval: 7s
      timeout: 3s
      retries: 7
      start_period: 10s 
    depends_on:
      - m1
    # restart: always

  s1:
    build: 
      context: .
      target: hadoop
    container_name: s1
    hostname: s1
    networks:
      - hnet
    volumes:
      - dn1:/usr/local/hadoop/hdfs/datanode
      - dtmp1:/usr/local/hadoop/tmp
      - dlogs1:/usr/local/hadoop/logs

    depends_on:
      m1:
        condition: service_healthy
      m2:
        condition: service_healthy
      m3:
        condition: service_healthy
    # restart: always

  # s2:
  #   build: 
  #     context: .
  #     target: hadoop
  #   container_name: s2
  #   hostname: s2
  #   networks:
  #     - hnet
  #   volumes:
  #     - dn2:/usr/local/hadoop/hdfs/datanode
  #     - dtmp2:/usr/local/hadoop/tmp
  #     - dlogs2:/usr/local/hadoop/logs
      
  #   depends_on:
  #     m1:
  #       condition: service_healthy
  #     m2:
  #       condition: service_healthy
  #     m3:
  #       condition: service_healthy
  #   restart: always

  postgres:
    image: postgres:13
    container_name: hive_postgres
    hostname: hive_db
    environment:
      POSTGRES_PASSWORD: 123
      POSTGRES_USER: hiveuser
      POSTGRES_DB: metastore
    volumes:
      - metastore:/var/lib/postgresql/data
    networks:
      - hnet
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U hiveuser -d metastore"]
      interval: 7s
      timeout: 7s
      retries: 7
      start_period: 9s 
    # restart: always

  h1:
    build: 
      context: .
      target: hive
    container_name: h1
    hostname: h1
    # volumes:
    #   -
    networks:
      - hnet
    depends_on:
      postgres:
        condition: service_healthy
      m1:
        condition: service_healthy
      m2:
        condition: service_healthy
      m3:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "ps aux | grep -i 'HiveMetaStore' | grep -v grep"]
      interval: 7s
      timeout: 7s
      retries: 10
      start_period: 15s
    # restart: always     
  h2:
    build: 
      context: .
      target: hive
    container_name: h2
    hostname: h2
    # volumes:
    #   - 
    ports:
        - "10000:10000"
        - "10002:10002"
    networks:
      - hnet
    depends_on:
      h1:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "ps aux | grep -i 'HiveServer2' | grep -v grep"]
      interval: 7s
      timeout: 7s
      retries: 10
      start_period: 15s
    environment:
      - HADOOP_CLASSPATH=/usr/local/tez/conf:/usr/local/tez/tez-mapreduce-0.10.3.jar
    # restart: always



networks:
  hnet:
    driver: bridge

volumes:
  nn1:
  j1:
  zk1:
  nn2:
  j2:
  zk2:
  nn3:
  j3:
  zk3:
  dn1:
  dtmp1:
  dlogs1:
  dn2:
  dtmp2:
  dlogs2:
  metastore:


